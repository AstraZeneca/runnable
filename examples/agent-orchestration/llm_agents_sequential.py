"""
Example: Sequential LLM/AI Agent Orchestration

This example shows how to orchestrate multiple AI agents in sequence:
1. Document Analyzer - extracts key information from text
2. Content Summarizer - creates structured summaries
3. Sentiment Analyzer - analyzes emotional tone
4. Report Generator - creates final formatted report

Each agent specializes in one task and passes results to the next.
"""

from runnable import Pipeline, PythonTask, pickled
import json
from typing import Dict, Any


def analyze_document(document_text: str) -> Dict[str, Any]:
    """
    Agent 1: Document Analyzer
    Simulates an AI agent that extracts key information from documents
    """
    # In reality, this would call Claude API, OpenAI, etc.
    print(f"ðŸ” Document Analyzer processing {len(document_text)} characters...")

    # Mock AI agent response
    analysis = {
        "document_type": "business_report",
        "key_entities": ["Q3 Revenue", "Customer Satisfaction", "Market Growth"],
        "main_topics": ["Financial Performance", "Customer Metrics", "Strategic Goals"],
        "word_count": len(document_text.split()),
        "complexity_score": 0.75,
        "original_text": document_text
    }

    print(f"âœ… Extracted {len(analysis['key_entities'])} entities and {len(analysis['main_topics'])} topics")
    return analysis


def summarize_content(analysis_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Agent 2: Content Summarizer
    Takes document analysis and creates structured summaries
    """
    print("ðŸ“ Content Summarizer processing analysis data...")

    # Mock AI summarization
    summary = {
        "executive_summary": f"Document analysis reveals focus on {', '.join(analysis_data['main_topics'])}",
        "key_points": [
            f"Document contains {analysis_data['word_count']} words",
            f"Complexity score: {analysis_data['complexity_score']}",
            f"Primary entities: {', '.join(analysis_data['key_entities'])}"
        ],
        "structured_data": {
            "metrics": analysis_data["key_entities"],
            "themes": analysis_data["main_topics"]
        },
        "original_analysis": analysis_data
    }

    print(f"âœ… Created summary with {len(summary['key_points'])} key points")
    return summary


def analyze_sentiment(summary_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Agent 3: Sentiment Analyzer
    Analyzes emotional tone and sentiment of the content
    """
    print("ðŸ˜Š Sentiment Analyzer processing summary...")

    # Mock sentiment analysis
    sentiment_analysis = {
        "overall_sentiment": "positive",
        "confidence": 0.82,
        "emotion_scores": {
            "optimism": 0.7,
            "concern": 0.3,
            "confidence": 0.8,
            "urgency": 0.4
        },
        "sentiment_summary": "The document exhibits positive sentiment with high confidence levels",
        "previous_data": summary_data
    }

    print(f"âœ… Sentiment: {sentiment_analysis['overall_sentiment']} (confidence: {sentiment_analysis['confidence']})")
    return sentiment_analysis


def generate_report(sentiment_data: Dict[str, Any]) -> str:
    """
    Agent 4: Report Generator
    Creates final formatted report combining all agent insights
    """
    print("ðŸ“Š Report Generator creating final output...")

    # Extract data from previous agents
    original_analysis = sentiment_data["previous_data"]["original_analysis"]
    summary = sentiment_data["previous_data"]
    sentiment = sentiment_data

    report = f"""
# AI Agent Analysis Report

## Document Overview
- **Type**: {original_analysis['document_type']}
- **Word Count**: {original_analysis['word_count']}
- **Complexity**: {original_analysis['complexity_score']}/1.0

## Key Findings
{chr(10).join(f"- {point}" for point in summary['key_points'])}

## Sentiment Analysis
- **Overall Sentiment**: {sentiment['overall_sentiment']}
- **Confidence Level**: {sentiment['confidence']:.1%}
- **Emotional Tone**: {sentiment['sentiment_summary']}

## Entity & Topic Analysis
**Key Entities**: {', '.join(original_analysis['key_entities'])}
**Main Topics**: {', '.join(original_analysis['main_topics'])}

## Executive Summary
{summary['executive_summary']}

---
*Report generated by sequential AI agent pipeline*
"""

    print("âœ… Final report generated successfully")
    return report.strip()


def main():
    """Execute the sequential LLM agent pipeline"""

    # Sample document to process
    sample_document = """
    Our Q3 business report shows significant growth across key metrics.
    Customer satisfaction has increased by 15% while revenue grew 23% year-over-year.
    Market expansion into the European sector exceeded expectations with
    strong adoption of our core products. Strategic initiatives around
    digital transformation continue to drive operational efficiency.
    """

    # Create sequential agent pipeline
    pipeline = Pipeline([
        PythonTask(
            function=analyze_document,
            name="document_analyzer",
            kwargs={"document_text": sample_document},
            returns=[pickled("analysis_result")]
        ),

        PythonTask(
            function=summarize_content,
            name="content_summarizer",
            kwargs={"analysis_data": pickled("analysis_result")},
            returns=[pickled("summary_result")]
        ),

        PythonTask(
            function=analyze_sentiment,
            name="sentiment_analyzer",
            kwargs={"summary_data": pickled("summary_result")},
            returns=[pickled("sentiment_result")]
        ),

        PythonTask(
            function=generate_report,
            name="report_generator",
            kwargs={"sentiment_data": pickled("sentiment_result")},
            returns=[pickled("final_report")]
        )
    ])

    print("ðŸš€ Starting Sequential LLM Agent Pipeline")
    print("=" * 50)

    # Execute pipeline
    results = pipeline.execute()

    print("\n" + "=" * 50)
    print("ðŸ“„ FINAL REPORT:")
    print("=" * 50)
    print(results["final_report"])


if __name__ == "__main__":
    main()
